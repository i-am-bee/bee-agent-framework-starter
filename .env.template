# LLM Provider (watsonx/ollama/openai/groq/bam)
LLM_BACKEND="ollama"

## WatsonX
# WATSONX_API_KEY=""
# WATSONX_PROJECT_ID=""
# WATSONX_MODEL="meta-llama/llama-3-1-70b-instruct"
# WATSONX_REGION="us-south"

## Ollama
# OLLAMA_HOST="http://0.0.0.0:11434"
# OLLAMA_MODEL="llama3.1:8b"

## OpenAI
# OPENAI_API_KEY=""
# OPENAI_MODEL="gpt-4o"

## Groq
# GROQ_API_KEY=""
# GROQ_MODEL="llama-3.1-70b-versatile"

## BAM
# GENAI_API_KEY=""
# GENAI_MODEL="meta-llama/llama-3-1-70b-instruct"

## Azure OpenAI
# OPENAI_MODEL="gpt-4o-mini"
# OPENAI_API_VERSION="2024-08-01-preview"
# AZURE_DEPLOYMENT_NAME=""
# AZURE_OPENAI_API_KEY=""
# AZURE_OPENAI_ENDPOINT=""

## VertexAI
# VERTEXAI_MODEL="gemini-1.5-flash-001"
# VERTEXAI_LOCATION="us-central1"
# VERTEXAI_PROJECT=""

# Tools
CODE_INTERPRETER_URL="http://127.0.0.1:50051"

# Framework related
BEE_FRAMEWORK_LOG_PRETTY=true
BEE_FRAMEWORK_LOG_LEVEL="info"
BEE_FRAMEWORK_LOG_SINGLE_LINE="false"
