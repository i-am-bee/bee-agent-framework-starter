# LLM Provider (watsonx/ollama/openai/groq)
LLM_CHAT_MODEL_NAME="ollama:llama3.1"

# For Ollama LLM Adapter
# OLLAMA_CHAT_MODEL=""
# OLLAMA_EMBEDDING_MODEL=""
# OLLAMA_BASE_URL=""

# For Watsonx LLM Adapter
# WATSONX_CHAT_MODEL=""
# WATSONX_EMBEDDING_MODEL=""
# WATSONX_API_KEY=""
# WATSONX_PROJECT_ID=""
# WATSONX_SPACE_ID=""
# WATSONX_VERSION=""
# WATSONX_REGION=""

# For OpenAI LLM Adapter
# OPENAI_CHAT_MODEL=""
# OPENAI_EMBEDDING_MODEL=""
# OPENAI_API_ENDPOINT=""
# OPENAI_API_KEY=""
# OPENAI_API_HEADERS=""

# For Azure OpenAI LLM Adapter
# AZURE_OPENAI_CHAT_MODEL=""
# AZURE_OPENAI_EMBEDDING_MODEL=""
# AZURE_OPENAI_API_KEY=""
# AZURE_OPENAI_API_ENDPOINT=""
# AZURE_OPENAI_API_RESOURCE=""
# AZURE_OPENAI_API_VERSION=""

# For Groq LLM Adapter
# GROQ_CHAT_MODEL=""
# GROQ_EMBEDDING_MODEL=""
# GROQ_API_HOST=""
# GROQ_API_KEY=""

# For Google Vertex Adapter
# GOOGLE_VERTEX_CHAT_MODEL=""
# GOOGLE_VERTEX_EMBEDDING_MODEL=""
# GOOGLE_VERTEX_PROJECT=""
# GOOGLE_VERTEX_ENDPOINT=""
# GOOGLE_VERTEX_LOCATION=""
# GOOGLE_APPLICATION_CREDENTIALS=""

# For Amazon Bedrock
# AWS_CHAT_MODEL=""
# AWS_EMBEDDING_MODEL=""
# AWS_ACCESS_KEY_ID=""
# AWS_SECRET_ACCESS_KEY=""
# AWS_REGION=""
# AWS_SESSION_TOKEN=""

# Tools
CODE_INTERPRETER_URL="http://127.0.0.1:50081"

# Framework related
BEE_FRAMEWORK_LOG_PRETTY=true
BEE_FRAMEWORK_LOG_LEVEL="info"
BEE_FRAMEWORK_LOG_SINGLE_LINE="false"

BEE_FRAMEWORK_INSTRUMENTATION_ENABLED="true"
OTEL_EXPORTER_OTLP_ENDPOINT="http://127.0.0.1:4002"
OTEL_EXPORTER_OTLP_HEADERS="x-bee-authorization=testing-api-key"
