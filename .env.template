# LLM Provider (watsonx/ollama/openai/groq/bam)
LLM_BACKEND=ollama

## WatsonX
# WATSONX_API_KEY=
# WATSONX_PROJECT_ID=
# WATSONX_MODEL="meta-llama/llama-3-1-70b-instruct"
# WATSONX_REGION="us-south"

## Ollama
# OLLAMA_HOST=http://0.0.0.0:11434
# OLLAMA_MODEL="llama3.1:8b"

## OpenAI
# OPENAI_API_KEY=
# OPENAI_MODEL="gpt-4o"

## Groq
# GROQ_API_KEY=
# GROQ_MODEL="llama-3.1-70b-versatile"

## BAM
# GENAI_API_KEY=
# GENAI_MODEL="meta-llama/llama-3-1-70b-instruct"

# Tools
CODE_INTERPRETER_URL=http://127.0.0.1:50051

# Framework related
BEE_FRAMEWORK_LOG_PRETTY=true
BEE_FRAMEWORK_LOG_LEVEL="info"
BEE_FRAMEWORK_LOG_SINGLE_LINE="false"
